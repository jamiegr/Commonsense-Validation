{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Nonsense classification evaluation.ipynb","provenance":[{"file_id":"1o3jg0paBrV4VedlGT7PIiwwRKSSKfzrz","timestamp":1628974326689},{"file_id":"1IRKW-Avy5fg_CyveLf2hfte-etCvrrPn","timestamp":1628610134773},{"file_id":"1a0oAOl25tEbwJgYk94_okLllEvB7a0pd","timestamp":1627316748311}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e14d2b71d42245fe9b95c70302038e3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9c9a3dfa67ed4473932fa5850e8a6313","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_03f959b50cfd4756b10c99239e86f507","IPY_MODEL_7be30e9be05142218166165d558b70d7","IPY_MODEL_a0c7250286744180b0d788ad524b57bb"]}},"9c9a3dfa67ed4473932fa5850e8a6313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03f959b50cfd4756b10c99239e86f507":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71d06f0a87a745ce8dd3996f7a30cf0b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_120d6923965947078c64910779afea68"}},"7be30e9be05142218166165d558b70d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_52be22886fd3461c8d181d002e3b0300","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":710,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":710,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b99c8239c6e4bee9883ace181209844"}},"a0c7250286744180b0d788ad524b57bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7cedd7986a446229f391a96d5ca46cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 710/710 [00:00&lt;00:00, 26.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9e9d7d4bc2f4161822a7bd4eba8d419"}},"71d06f0a87a745ce8dd3996f7a30cf0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"120d6923965947078c64910779afea68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52be22886fd3461c8d181d002e3b0300":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2b99c8239c6e4bee9883ace181209844":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7cedd7986a446229f391a96d5ca46cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a9e9d7d4bc2f4161822a7bd4eba8d419":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab668f1f71704e838eed897ed12077fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e2c240fa56db4111be722c7ab09a4c27","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_033ecd94972f4429971cc1a07ee7ef15","IPY_MODEL_c0b59fbfc0fc49b1938df2799c3dcb56","IPY_MODEL_9380d35834a84138bc99b0acfe327e9b"]}},"e2c240fa56db4111be722c7ab09a4c27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"033ecd94972f4429971cc1a07ee7ef15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e82a01b967c0493fa5a79a37a4be0413","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_99294712b43e42d698096c38e0857621"}},"c0b59fbfc0fc49b1938df2799c3dcb56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_04a7065b84e2493a871f9d395ae9e6ec","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":892728632,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":892728632,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_58a23f23d841437b969b2207d41cc54f"}},"9380d35834a84138bc99b0acfe327e9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3f423ab42a9145438db3ca67fa957854","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 893M/893M [01:19&lt;00:00, 11.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54f15eb132a14cf09f6b01735110eaf3"}},"e82a01b967c0493fa5a79a37a4be0413":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"99294712b43e42d698096c38e0857621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04a7065b84e2493a871f9d395ae9e6ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"58a23f23d841437b969b2207d41cc54f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f423ab42a9145438db3ca67fa957854":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"54f15eb132a14cf09f6b01735110eaf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ca5e537ba584d0ead029108b3ce4905":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_90fd2267fdbe4b17a7aba355c5496757","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_72b9ccafcf5044109a415a430212996d","IPY_MODEL_71107e9b145f423a9617db5622ab288c","IPY_MODEL_cf41ea932736426daed61599b67ecae4"]}},"90fd2267fdbe4b17a7aba355c5496757":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72b9ccafcf5044109a415a430212996d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ac6328f04ed449a8a6324c237f96cda5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74930d10186e4da9a4e6413c6c345775"}},"71107e9b145f423a9617db5622ab288c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e25d68be61ba4f279825647506752525","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":760289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f12c1c774024314a88071090b7452e1"}},"cf41ea932736426daed61599b67ecae4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8edbb060ef084dd0abfba52199394b5b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 760k/760k [00:00&lt;00:00, 621kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d19e1c273d04847a61ac4769308f35d"}},"ac6328f04ed449a8a6324c237f96cda5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"74930d10186e4da9a4e6413c6c345775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e25d68be61ba4f279825647506752525":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3f12c1c774024314a88071090b7452e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8edbb060ef084dd0abfba52199394b5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d19e1c273d04847a61ac4769308f35d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"JXAqfnIUda3X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629813116179,"user_tz":-120,"elapsed":33841,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}},"outputId":"3fae5cde-2979-419e-dd9e-acb718bdc2c5"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","DATA_DIR = '/content/gdrive/MyDrive/MSc Thesis/Data/'\n","path_to_model = '/content/gdrive/MyDrive/MSc Thesis/Colab/models/Best individual model.pt'\n","bert_model = \"albert-xxlarge-v2\"  # 'albert-base-v2', 'albert-large-v2', 'albert-xlarge-v2', 'albert-xxlarge-v2', 'bert-base-uncased', 'bert-large-uncased' ...\n","bs = 16  # batch size\n","mode = \"individual\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0dsNLf6MaI44"},"source":["## Initial setup"]},{"cell_type":"markdown","metadata":{"id":"b6lgZi89aNCu"},"source":["Installing necessary libraries not included in default colab environment"]},{"cell_type":"code","metadata":{"id":"sh88IMhCaiaL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629813120649,"user_tz":-120,"elapsed":4475,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}},"outputId":"5ed12c13-965e-461f-d0f0-56f192c4a4b8"},"source":["!pip install transformers==3.1.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers==3.1.0\n","  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n","\u001b[K     |████████████████████████████████| 884 kB 3.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (21.0)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 80.7 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc2\n","  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 76.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 72.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.62.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.45 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fmZyu1bmab98"},"source":["Importing libraries"]},{"cell_type":"code","metadata":{"id":"c9BH4gEDar3s","executionInfo":{"status":"ok","timestamp":1629813125427,"user_tz":-120,"elapsed":4782,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import os\n","import matplotlib.pyplot as plt\n","import copy\n","import torch.optim as optim\n","import random\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.cuda.amp import autocast, GradScaler\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uoJCYFMEeX_x"},"source":["## Loading the data"]},{"cell_type":"markdown","metadata":{"id":"bJYR_qCPeeFK"},"source":["The following functions allow us to load the SemEval-2020 Task 4 Subtask A data either in the form of a sentence pair classification task as was originally intended or as individually labelled sentences."]},{"cell_type":"code","metadata":{"id":"y0DzL7elwHFV","executionInfo":{"status":"ok","timestamp":1629813125427,"user_tz":-120,"elapsed":13,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}}},"source":["def load_sentence_pairs(X_path, y_path):\n","    X = pd.read_csv(X_path).drop(columns=[\"id\"])\n","    y = pd.read_csv(y_path, header=None).drop(columns=[0])\n","    X = X.rename(columns={\"sent0\": \"sentence1\", \"sent1\": \"sentence2\"})\n","    y = y.rename(columns={1: \"label\"})\n","    df = pd.concat([X, y], axis=1)\n","    # Removing rows where both sentences are the same\n","    # df=df[df[\"sentence1\"].str.lower()!=df[\"sentence2\"].str.lower()]\n","\n","\n","    return df\n","\n","def load_individual_sentences(X_path, y_path):\n","    X = pd.read_csv(X_path).drop(columns=[\"id\"])\n","    y = pd.read_csv(y_path, header=None).iloc[: , 1:]\n","\n","    X_new = []\n","    y_new = []\n","\n","    for index, row in y.iterrows():\n","        # Ignore rows where both sentences are the same\n","        if X[\"sent0\"][index].lower() != X[\"sent1\"][index].lower():\n","            X_new.append(X[\"sent0\"][index])\n","            X_new.append(X[\"sent1\"][index])\n","            if y[1][index] == 0:\n","                y_new.append(1)\n","                y_new.append(0)\n","            else:\n","                y_new.append(0)\n","                y_new.append(1)\n","        else:\n","            print(index)\n","    \n","    df = pd.DataFrame({\"sentence1\": X_new, \"label\": y_new})\n","\n","    return df"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwuD3_d4ZC2w","executionInfo":{"status":"ok","timestamp":1629813125428,"user_tz":-120,"elapsed":13,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}}},"source":["class CustomDataset(Dataset):\n","\n","    def __init__(self, data, maxlen, with_labels=True, bert_model='albert-xxlarge-v2'):\n","\n","        self.data = data  # pandas dataframe\n","        #Initialize the tokenizer\n","        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)  \n","\n","        self.maxlen = maxlen\n","        self.with_labels = with_labels \n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        # Selecting sentence1 and sentence2 at the specified index in the data frame\n","        sent1 = str(self.data.loc[index, 'sentence1'])\n","        # Account for single sentence or sentence pair problems\n","        if 'sentence2' in self.data.columns:\n","            sent2 = str(self.data.loc[index, 'sentence2'])\n","\n","            # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n","            encoded = self.tokenizer(sent1, sent2, \n","                                        padding='max_length',  # Pad to max_length\n","                                        truncation=True,  # Truncate to max_length\n","                                        max_length=self.maxlen,  \n","                                        return_tensors='pt')  # Return torch.Tensor objects\n","        else:\n","            # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n","            encoded = self.tokenizer(sent1, \n","                                        padding='max_length',  # Pad to max_length\n","                                        truncation=True,  # Truncate to max_length\n","                                        max_length=self.maxlen,  \n","                                        return_tensors='pt')  # Return torch.Tensor objects\n","        \n","        token_ids = encoded['input_ids'].squeeze(0)  # tensor of token ids\n","        attn_masks = encoded['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n","        token_type_ids = encoded['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n","\n","        if self.with_labels:  # True if the dataset has labels\n","            label = self.data.loc[index, 'label']\n","            return token_ids, attn_masks, token_type_ids, label  \n","        else:\n","            return token_ids, attn_masks, token_type_ids"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2yfuMFpd-KcG"},"source":["## Defining model class and function for converting model outputs to probabilities\n"]},{"cell_type":"code","metadata":{"id":"IYr_y9t8tqhX","executionInfo":{"status":"ok","timestamp":1629813125428,"user_tz":-120,"elapsed":13,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}}},"source":["class BertClassifier(nn.Module):\n","\n","    def __init__(self, bert_model=\"albert-xxlarge-v2\", freeze_bert=False, dropout_rate=0.2):\n","        super(BertClassifier, self).__init__()\n","        #  Instantiating BERT-based model object\n","        self.bert_layer = AutoModel.from_pretrained(bert_model)\n","\n","        #  Fix the hidden-state size of the encoder outputs (If you want to add other pre-trained models here, search for the encoder output size)\n","        if bert_model == \"albert-base-v2\":  # 12M parameters\n","            hidden_size = 768\n","        elif bert_model == \"albert-large-v2\":  # 18M parameters\n","            hidden_size = 1024\n","        elif bert_model == \"albert-xlarge-v2\":  # 60M parameters\n","            hidden_size = 2048\n","        elif bert_model == \"albert-xxlarge-v2\":  # 235M parameters\n","            hidden_size = 4096\n","        elif bert_model == \"bert-base-uncased\": # 110M parameters\n","            hidden_size = 768\n","        elif bert_model == \"bert-large-uncased\": #336M parameters\n","            hidden_size = 1024\n","\n","        # Freeze bert layers and only train the classification layer weights\n","        if freeze_bert:\n","            for p in self.bert_layer.parameters():\n","                p.requires_grad = False\n","\n","        self.dropout = nn.Dropout(p=dropout_rate)\n","\n","        # Classification layer\n","        self.cls_layer = nn.Linear(hidden_size, 1)\n","\n","        # Activation function\n","        self.activation = nn.Sigmoid()\n","\n","\n","    @autocast()  # run in mixed precision\n","    def forward(self, input_ids, attn_masks, token_type_ids):\n","        '''\n","        Inputs:\n","            -input_ids : Tensor  containing token ids\n","            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n","            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n","        '''\n","\n","        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n","        cont_reps, pooler_output = self.bert_layer(input_ids, attn_masks, token_type_ids)\n","\n","        # Feeding to the classifier layer the last layer hidden-state of the [CLS] token further processed by a\n","        # Linear Layer and a Tanh activation. The Linear layer weights were trained from the sentence order prediction (ALBERT) or next sentence prediction (BERT)\n","        # objective during pre-training.\n","        logits = self.cls_layer(self.dropout(pooler_output))\n","\n","        return logits"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnX-ySwuuoZ_","executionInfo":{"status":"ok","timestamp":1629813125428,"user_tz":-120,"elapsed":12,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}}},"source":["def set_seed(seed):\n","    \"\"\" Set all seeds to make results reproducible \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","def get_probs_from_logits(logits):\n","    \"\"\"\n","    Converts a tensor of logits into an array of probabilities by applying the sigmoid function\n","    \"\"\"\n","    probs = torch.sigmoid(logits.unsqueeze(-1))\n","    return probs.detach().cpu().numpy() "],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p36KcgMg-Pe7"},"source":["## Testing and Evaluation"]},{"cell_type":"code","metadata":{"id":"kjnbv-h80B9w","executionInfo":{"status":"ok","timestamp":1629813125429,"user_tz":-120,"elapsed":13,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}}},"source":["def evaluate_test_set(net, device, dataloader):\n","    net.eval()\n","\n","    all_preds = pd.Series([], dtype='uint8')\n","    all_probs = pd.Series([], dtype='uint8')\n","    all_labels = pd.Series([], dtype='uint8')\n","\n","    with torch.no_grad():\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):\n","            # Converting data to cuda tensors\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","            \n","            # Getting probabilities then predictions from outputted logits\n","            logits = net(seq, attn_masks, token_type_ids)\n","            probs = pd.Series(get_probs_from_logits(logits.squeeze(-1)).squeeze(-1).tolist())\n","            preds=(probs>=0.5).astype('uint8')\n","            all_probs = all_probs.append(probs, ignore_index=True)\n","            all_preds = all_preds.append(preds, ignore_index=True)\n","            # Converting labels to CPU tensor so that it can be converted to Series\n","            all_labels = all_labels.append(pd.Series(labels.cpu()).astype('uint8'), ignore_index=True)\n","\n","    return {\"accuracy\": accuracy_score(all_labels, all_preds), \"precision\": precision_score(all_labels, all_preds),\n","            \"recall\": recall_score(all_labels, all_preds), \"f1\": f1_score(all_labels, all_preds),\n","            \"AUROC\": roc_auc_score(all_labels, all_probs)}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uz4HShHdhZv8","executionInfo":{"status":"ok","timestamp":1629813125429,"user_tz":-120,"elapsed":12,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}}},"source":["def evaluate_individual_sentence(net, device, tokenizer, sent):\n","    # The best performing model on the test set with individual sentences was the model\n","    # from the initial experimentation (before hyperparameter tuning)\n","    with torch.no_grad():\n","        encoded = tokenizer(sent, padding='max_length', truncation=True, max_length=32, return_tensors='pt')\n","        token_ids = encoded['input_ids'].to(device)\n","        attn_masks = encoded['attention_mask'].to(device)\n","        token_type_ids = encoded['token_type_ids'].to(device)\n","        logits = net(token_ids, attn_masks, token_type_ids)\n","        probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n","\n","        if probs[0] > 0.5:\n","            print(\"Input sentence:\", sent)\n","            print(\"Prediction: Nonsensical\")\n","            print(\"Prediction probability:\", round(probs[0]*100, 2))\n","        elif probs[0] < 0.5:\n","            print(\"Input sentence:\", sent)\n","            print(\"Prediction: Sensical\")\n","            print(\"Prediction probability:\", round((1-probs[0])*100, 2))\n","        else:\n","            print(\"Input sentence:\", sent)\n","            print(\"Prediction: Uncertain\")\n","        print(\"\")\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"_cwyKIhUmjBB","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["e14d2b71d42245fe9b95c70302038e3e","9c9a3dfa67ed4473932fa5850e8a6313","03f959b50cfd4756b10c99239e86f507","7be30e9be05142218166165d558b70d7","a0c7250286744180b0d788ad524b57bb","71d06f0a87a745ce8dd3996f7a30cf0b","120d6923965947078c64910779afea68","52be22886fd3461c8d181d002e3b0300","2b99c8239c6e4bee9883ace181209844","b7cedd7986a446229f391a96d5ca46cb","a9e9d7d4bc2f4161822a7bd4eba8d419","ab668f1f71704e838eed897ed12077fc","e2c240fa56db4111be722c7ab09a4c27","033ecd94972f4429971cc1a07ee7ef15","c0b59fbfc0fc49b1938df2799c3dcb56","9380d35834a84138bc99b0acfe327e9b","e82a01b967c0493fa5a79a37a4be0413","99294712b43e42d698096c38e0857621","04a7065b84e2493a871f9d395ae9e6ec","58a23f23d841437b969b2207d41cc54f","3f423ab42a9145438db3ca67fa957854","54f15eb132a14cf09f6b01735110eaf3","8ca5e537ba584d0ead029108b3ce4905","90fd2267fdbe4b17a7aba355c5496757","72b9ccafcf5044109a415a430212996d","71107e9b145f423a9617db5622ab288c","cf41ea932736426daed61599b67ecae4","ac6328f04ed449a8a6324c237f96cda5","74930d10186e4da9a4e6413c6c345775","e25d68be61ba4f279825647506752525","3f12c1c774024314a88071090b7452e1","8edbb060ef084dd0abfba52199394b5b","5d19e1c273d04847a61ac4769308f35d"]},"executionInfo":{"status":"ok","timestamp":1629813240330,"user_tz":-120,"elapsed":114913,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}},"outputId":"5e3346cf-b556-412b-d45d-df17536f5681"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = BertClassifier(bert_model)\n","net.load_state_dict(torch.load(path_to_model))\n","net.to(device)\n","tokenizer = AutoTokenizer.from_pretrained(bert_model)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e14d2b71d42245fe9b95c70302038e3e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/710 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab668f1f71704e838eed897ed12077fc","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/893M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ca5e537ba584d0ead029108b3ce4905","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"yBCBDB67HTp_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629813301173,"user_tz":-120,"elapsed":60853,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}},"outputId":"8cb49ea4-e0ff-4254-d16f-9954b82623fd"},"source":["set_seed(8)\n","\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","if mode == \"pairs\":\n","    maxlen = 64 \n","    test_df = load_sentence_pairs(DATA_DIR+'test_data.csv', DATA_DIR+'test_labels.csv')\n","elif mode == \"individual\":\n","    maxlen = 32\n","    test_df = load_individual_sentences(DATA_DIR+'test_data.csv', DATA_DIR+'test_labels.csv')\n","else:\n","    print(\"WARNING: invalid running mode, please select 'pairs' or 'individual'\")\n","\n","test_set = CustomDataset(test_df, maxlen, bert_model)\n","test_loader = DataLoader(test_set, batch_size=bs, num_workers=2, shuffle=True)\n","\n","results = evaluate_test_set(net, device, test_loader)\n","print('')\n","print(results)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["100%|██████████| 125/125 [00:57<00:00,  2.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","{'accuracy': 0.8925, 'precision': 0.9234088457389428, 'recall': 0.856, 'f1': 0.888427607680332, 'AUROC': 0.956616}\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BgpNn5fQwhpW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629813301174,"user_tz":-120,"elapsed":12,"user":{"displayName":"Jamie Grech","photoUrl":"","userId":"02325331054203573121"}},"outputId":"f1ca3de1-c53b-4a14-eea3-04b4cc83478d"},"source":["evaluate_individual_sentence(net, device, tokenizer, \"The sky is blue\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Input sentence: The sky is blue\n","Prediction: Sensical\n","Prediction probability: 98.09\n","\n"],"name":"stdout"}]}]}